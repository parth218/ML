# -*- coding: utf-8 -*-
"""ML LAB -5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y9KW6Ve5OsWIyfHX-EC46eVMtONm0mV-

# **MACHINE LEARNING LAB - 5**

# **Problem Statement : Performing handwritten digit classification using logistic regression**

**Import Libraries**
"""

import pandas as pd  
import numpy as np
import seaborn as sns 
import matplotlib.pyplot as plt 
import os 
from sklearn.preprocessing import StandardScaler 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import GridSearchCV 
from sklearn.metrics import accuracy_score 
import warnings 
warnings.filterwarnings("ignore")

"""**Load the data**"""

os.environ['KAGGLE_CONFIG_DIR'] ='/content'

!kaggle competitions download -c digit-recognizer

!unzip \*.zip && rm *.zip

df = pd.read_csv("train.csv") 
df.head()

x = df.drop('label', axis=1).values 
y = df['label'].values

"""**Splitting data into Train and test sets with Stratified Sampling using train_test_split()**"""

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 45)

"""**Data Preprocessing using column standardisation. Use sklearn.preprocessing.StandardScaler().**"""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train) 
X_test_scaled = scaler.transform(X_test)

parameters = {'C': [0.01, 0.1, 1, 10]}
grid = GridSearchCV(estimator=LogisticRegression(), param_grid=parameters, cv=4, verbose=2, return_train_score=True)
grid.fit(X_train_scaled, y_train)

grid.cv_results_

"""**Plotting Graphs CV-accuracy vs Hyperparameters**"""

C_vals = [str(x) for x in parameters['C']]

plt.xlabel("C")
plt.ylabel("cv-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_test_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_test_score'], linestyle="dashed")
plt.ylim(0.85,.95)
plt.xticks(C_vals)
plt.show()

"""**Plotting Graphs train-accuracy vs Hyperparameters**"""

plt.xlabel("C")
plt.ylabel("train-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_train_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_train_score'], linestyle="dashed")
plt.ylim(0.9,1.00)
plt.xticks(C_vals)
plt.show()

print("Best parameters:", grid.best_params_)
print("Best score:", grid.best_score_)

for c in parameters['C']:
    model = LogisticRegression(C=c)

    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print(c, accuracy_score(y_test, y_pred))