# -*- coding: utf-8 -*-
"""LAB - 6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ltt9bjkPnjeEgiVqWjcAoTXW-NPuKn6A

# **MACHINE LEARNING LAB - 6**

# **Problem Statement : Performing handwritten digit classification using SVM and Neural Network**

**Import Libraries**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
import os
from sklearn.linear_model import LogisticRegression 
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.neural_network import MLPClassifier
import warnings
warnings.filterwarnings("ignore")

"""**Load the data**"""

os.environ['KAGGLE_CONFIG_DIR'] ='/content'

!kaggle competitions download -c digit-recognizer 
!unzip \*.zip && rm *.zip

df = pd.read_csv("train.csv")
df.head()

x = df.drop('label', axis=1).values
y = df['label'].values

"""**Exercise 1: Perform handwritten digit classification using Support Vector Machine (SVM) model. Plot “hyperparameter vs. train-accuracy” and “hyperparameter vs. cv-accuracy” graphs. Measure model performance on test data using following metrics: accuracy, confusion matrix, precision, recall and F1 Score.**

**Splitting data into Train and test sets with Stratified Sampling using train_test_split()**
"""

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state = 42)

parameters = {'kernel':['linear', 'rbf'], 'gamma':['scale', 'auto']}
grid = GridSearchCV(estimator=SVC(), param_grid=parameters, cv=4, verbose=2, n_jobs=-1, return_train_score=True)
grid.fit(X_train, y_train)

grid.cv_results_

"""**Plotting Graphs CV-accuracy vs Hyperparameters**"""

C_vals = ['gamma:scale; kernel:linear', 'gamma:scale; kernel:rbf', 'gamma:auto; kernel:rbf', 'gamma:auto; kernel:linear']

plt.xlabel("C")
plt.ylabel("cv-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_test_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_test_score'], linestyle="dashed")
plt.xticks(C_vals)
plt.show()

"""**Plotting Graphs train-accuracy vs Hyperparameters**"""

plt.xlabel("C")
plt.ylabel("train-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_train_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_train_score'], linestyle="dashed")
plt.xticks(C_vals)
plt.show()

model = SVC(gamma='scale', kernel='rbf')
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

"""**Exercise 2: Perform handwritten digit classification using neural network model with single hidden layer. Plot “hyperparameter vs. train-accuracy” and “hyperparameter vs. cv-accuracy” graphs. Measure model performance on test data using following metrics: accuracy, confusion matrix, precision, recall and F1 Score.** """

parameters = {'hidden_layer_sizes':[(50,), (100,)], 'learning_rate_init':[0.001, 0.0005]}
grid = GridSearchCV(MLPClassifier(), param_grid=parameters, cv=4, verbose=2, n_jobs=-1, return_train_score=True)
grid.fit(X_train, y_train)

grid.cv_results_

"""**Plotting Graphs CV-accuracy vs Hyperparameters**"""

C_vals = ["hidden layer': 50, 'learning rate': 0.001", 
         "hidden layer': 50, 'learning rate': 0.0002",
         "hidden layer': 20, 'learning rate': 0.001",
         "hidden layer': 20, 'learning rate': 0.0002"]

plt.xlabel("C")
plt.ylabel("cv-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_test_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_test_score'], linestyle="dashed")
plt.xticks(C_vals)
plt.show()

"""**Plotting Graphs train-accuracy vs Hyperparameters**"""

plt.xlabel("C")
plt.ylabel("train-accuracy")
plt.scatter(C_vals, grid.cv_results_['mean_train_score'], color='black')
plt.vlines(C_vals, 0, grid.cv_results_['mean_train_score'], linestyle="dashed")
plt.xticks(C_vals)
plt.show()

model = MLPClassifier(hidden_layer_sizes=100, learning_rate_init=0.0005)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

"""**Exercise 3: Compare the performances of logistic regression, SVM and neural networks models on MNIST dataset for digit recognition. Write your observation on the performances of these models**

We are using SVM, Neural Network and Logistic regression and the accuracy we get are as blow


*   SVM :- 96%
*   Neural Network :- 90%
* Logistic regression :- 91%
"""